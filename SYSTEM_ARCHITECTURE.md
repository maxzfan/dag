# Nexus System Architecture & Process Flow

## ğŸ—ï¸ System Overview

Nexus is a sophisticated voice AI conversation platform that combines real-time voice interaction with intelligent agent generation and deployment. The system operates in two distinct modes: **Journal Mode** (passive note-taking) and **Agent Mode** (active problem-solving and automation).

## ğŸ”„ Complete Process Flow

### 1. **User Interface Layer**
```
Frontend (React + TypeScript)
â”œâ”€â”€ Voice Recording Interface
â”œâ”€â”€ Real-time Speech-to-Text
â”œâ”€â”€ AI Response Display
â”œâ”€â”€ Text-to-Speech Playback
â””â”€â”€ Mode Switching (Journal â†” Agent)
```

### 2. **Backend Processing Layer**
```
Flask Server (Python)
â”œâ”€â”€ Speech-to-Text Processing (Fish Audio)
â”œâ”€â”€ AI Conversation Engine (OpenRouter + Claude)
â”œâ”€â”€ Text-to-Speech Generation (Fish Audio)
â”œâ”€â”€ Multi-Agent Orchestration
â””â”€â”€ Agent Generation & Deployment
```

### 3. **Agent Generation Pipeline**
```
DAG System (Dynamic Agent Generator)
â”œâ”€â”€ YAML Configuration Generation
â”œâ”€â”€ Fetch.ai Agent Code Generation
â”œâ”€â”€ Deployment Configuration
â””â”€â”€ Agent Lifecycle Management
```

---

## ğŸ¯ Detailed Component Connections

### **Frontend â†’ Backend Communication**

#### **Voice Recording Flow:**
1. **User clicks record** â†’ Browser microphone access
2. **Speech captured** â†’ Real-time transcription via Web Speech API
3. **Recording stops** â†’ Audio sent to backend for processing
4. **Backend processes** â†’ Fish Audio STT + OpenRouter AI
5. **Response generated** â†’ Text-to-speech via Fish Audio TTS
6. **Audio played** â†’ User hears AI response

#### **API Endpoints Used:**
```typescript
// Frontend API calls (App.tsx)
const apiBaseUrl = 'http://localhost:5001'

// Speech-to-Text
POST /speech-to-text
Content-Type: multipart/form-data
Body: audio file

// AI Conversation
POST /conversation
Content-Type: application/json
Body: { text: "user message" }

// Text-to-Speech
POST /text-to-speech
Content-Type: application/json
Body: { text: "AI response" }
```

#### **Vite Proxy Configuration:**
```typescript
// vite.config.ts
server: {
  proxy: {
    '/api': {
      target: 'http://localhost:5001',
      changeOrigin: true,
      rewrite: (path) => path.replace(/^\/api/, '')
    }
  }
}
```

---

### **Backend Processing Architecture**

#### **Multi-Agent Orchestration System:**

```python
# voice_server.py - Core orchestration logic
orchestrator_state = {
    "phase": None,                 # None | "detail" | "yaml"
    "pending_questions": None,     # list[str] | None
    "problem_brief": None,         # dict | None
    "detail_spec": None,           # dict | None
}
```

#### **Agent Mode Detection:**
1. **Journal Analysis** â†’ `_run_journal(user_text)`
   - Uses `PROMPT_JOURNAL` to analyze user input
   - Detects problems using `_is_problem_heuristic()`
   - Returns either summary or `ProblemBrief` JSON

2. **Detail Gathering** â†’ `_run_detail(problem_brief, user_text, current_spec)`
   - Uses `PROMPT_DETAIL` to ask clarifying questions
   - Builds detailed specification
   - Returns `DetailSpec` JSON when complete

3. **YAML Generation** â†’ `_run_yaml(detail_spec)`
   - Uses `PROMPT_YAML` to generate Fetch.ai agent configuration
   - Returns complete YAML configuration
   - Triggers agent generation pipeline

#### **Prompt System Architecture:**
```python
# Dynamic prompt loading system
PROMPT_JOURNAL = None  # Loaded from prompt_journal.md
PROMPT_DETAIL = None   # Loaded from prompt_detail.md  
PROMPT_YAML = None     # Loaded from prompt_yaml.md

# Can be updated dynamically from YAML content
def _extract_prompts_from_yaml(yaml_content: str) -> dict
```

---

### **Agent Generation Pipeline**

#### **YAML â†’ Fetch.ai Agent Process:**

1. **YAML Configuration** â†’ Generated by AI based on user requirements
2. **Agent Code Generation** â†’ `yamlToFetch.py` converts YAML to Python
3. **Deployment Setup** â†’ `deploy.py` prepares agent for deployment
4. **Agent Registration** â†’ Agent added to `agents_storage`

#### **DAG System Components:**

```python
# dag/yamlToFetch.py - Agent code generation
def generate_agent_from_yaml(yaml_path: str, output_path: str, output_dir: str):
    # 1. Parse YAML configuration
    # 2. Generate imports and dependencies
    # 3. Create agent instance with Fetch.ai SDK
    # 4. Generate protocol handlers
    # 5. Generate interval tasks
    # 6. Generate deployment configuration
    # 7. Write complete Python agent file
```

```python
# dag/deploy.py - Agent deployment
class FetchAgentDeployer:
    def setup_deployment(self):
        # 1. Create deployment environment
        # 2. Generate systemd service files
        # 3. Create deployment documentation
        # 4. Setup network configuration
```

---

## ğŸ”„ Complete User Journey

### **Scenario 1: Journal Mode (Passive)**
```
User: "I had a good day working on the frontend, made progress on components"
â†“
Frontend: Captures voice â†’ Sends to /conversation
â†“
Backend: _run_journal() â†’ PROMPT_JOURNAL â†’ Returns summary
â†“
Response: "Here's a summary of your progress: - Made progress on frontend UI components"
â†“
Frontend: Displays response â†’ Plays TTS audio
```

### **Scenario 2: Agent Mode (Active Problem Detection)**
```
User: "My build keeps failing every few hours and I have to manually restart it"
â†“
Frontend: Captures voice â†’ Sends to /conversation
â†“
Backend: _run_journal() â†’ Detects problem â†’ Returns ProblemBrief
â†“
Backend: _run_detail() â†’ Asks clarifying questions
â†“
User: "It's a CI/CD pipeline, runs every 2 hours, should notify me on Slack"
â†“
Backend: _run_yaml() â†’ Generates complete YAML configuration
â†“
Backend: _create_agent_from_yaml() â†’ Generates Fetch.ai agent
â†“
Response: "ğŸ¤– Agent Created! I've generated a new agent called 'CI Monitor'..."
â†“
Frontend: Shows agent in dashboard â†’ User can deploy/configure
```

---

## ğŸ—„ï¸ Data Storage & Persistence

### **Conversation Storage:**
```python
# backend/data/conversation-{uuid}.json
{
  "id": "conversation-uuid",
  "title": "Generated title",
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-01T00:00:00Z",
  "messages": [
    {
      "id": "message-uuid",
      "timestamp": "2024-01-01T00:00:00Z",
      "user_text": "User message",
      "ai_summary": "AI response",
      "model": "anthropic/claude-3-haiku"
    }
  ],
  "summary": "Generated conversation summary"
}
```

### **Agent Storage:**
```python
# In-memory agent storage
agents_storage = {
    "agents": [
        {
            "id": "agent-uuid",
            "name": "Generated Agent",
            "description": "AI-powered agent description",
            "status": "generated|deployed",
            "directory": "/path/to/agent/files",
            "yaml_content": "Complete YAML configuration"
        }
    ]
}
```

---

## ğŸ”§ Environment & Dependencies

### **Backend Dependencies:**
```txt
# requirements.txt
fish-audio-sdk      # Voice processing
flask               # Web framework
flask-cors          # CORS handling
openrouter          # AI API client
python-dotenv       # Environment variables
requests            # HTTP client
PyYAML              # YAML processing
```

### **Frontend Dependencies:**
```json
// package.json
{
  "dependencies": {
    "react": "^18.2.0",
    "@radix-ui/react-*": "UI components",
    "lucide-react": "Icons",
    "tailwindcss": "Styling"
  }
}
```

### **Required Environment Variables:**
```bash
# .env file
FISH_AUDIO_API_KEY=your_fish_audio_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

---

## ğŸš€ Deployment Architecture

### **Development Setup:**
1. **Backend**: `python3 voice_server.py` (Port 5001)
2. **Frontend**: `npm run dev` (Port 3000)
3. **Proxy**: Vite proxies `/api` requests to backend

### **Production Considerations:**
- **Backend**: Can be deployed to any Python hosting (Heroku, AWS, etc.)
- **Frontend**: Static build can be served from CDN
- **Agents**: Generated agents can be deployed to Fetch.ai network
- **Database**: Currently file-based, can be upgraded to PostgreSQL/MongoDB

---

## ğŸ” Key Integration Points

### **1. Voice Processing Chain:**
```
Browser Microphone â†’ Web Speech API â†’ Fish Audio STT â†’ OpenRouter AI â†’ Fish Audio TTS â†’ Browser Audio
```

### **2. AI Orchestration Chain:**
```
User Input â†’ Journal Analysis â†’ Problem Detection â†’ Detail Gathering â†’ YAML Generation â†’ Agent Creation
```

### **3. Agent Lifecycle:**
```
YAML Config â†’ Python Agent Code â†’ Deployment Files â†’ Fetch.ai Network â†’ Monitoring & Management
```

---

## ğŸ› ï¸ Development Workflow

### **Adding New Features:**
1. **Frontend Changes**: Modify React components in `frontend/src/`
2. **Backend Changes**: Update Flask routes in `backend/voice_server.py`
3. **Agent Logic**: Modify prompts in `backend/prompt_*.md` files
4. **DAG System**: Update `dag/yamlToFetch.py` for new agent capabilities

### **Testing the System:**
1. **Start Backend**: `cd backend && python3 voice_server.py`
2. **Start Frontend**: `cd frontend && npm run dev`
3. **Test Voice**: Use microphone to record and test conversation
4. **Test Agent Mode**: Describe a problem to trigger agent generation

---

## ğŸ“Š System Monitoring

### **Logs to Watch:**
- **Backend**: Flask server logs show API calls and processing
- **Frontend**: Browser console shows voice recording and API calls
- **Agent Generation**: DAG system logs show agent creation process

### **Key Metrics:**
- Voice recording success rate
- AI response quality and relevance
- Agent generation success rate
- Deployment success rate

---

This architecture provides a complete voice AI platform that can intelligently detect problems, gather requirements, and automatically generate deployable Fetch.ai agents for automation solutions.
